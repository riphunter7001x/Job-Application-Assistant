{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't scientists trust atoms? \\n\\nBecause they make up everything!\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model.invoke(\"tell me a joke \").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from pathlib import Path\n",
    "def _extract_from_pdf(file_path: Path) -> str:\n",
    "    converter = DocumentConverter()\n",
    "    result = converter.convert(file_path)\n",
    "    return result.document.export_to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from pathlib import Path\n",
    "def _extract_from_pdf(file_path: Path) -> str:\n",
    "    doc = fitz.open(file_path)\n",
    "    text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aditya Varpe\n",
      "adi.varpe117@gmail.com | +91 8275200921\n",
      "github| linkedin\n",
      "EXPERIENCE\n",
      "Ibind Systems Private Limited\n",
      "Jul 2024 - Present\n",
      "AI Engineer\n",
      "Bengaluru, India\n",
      "• Intelligent Document Management System: Orchestrated an Agentic Workflow using the LangGraph Frame-\n",
      "work to automate classification, summarization, and data extraction, improving document retrieval accuracy by\n",
      "25%.\n",
      "• Cross-Border Payment AI Solution: Developed an AI-driven fraud detection and compliance automation sys-\n",
      "tem, reducing transaction processing time by 50%.\n",
      "• Regulatory Compliance Automation: Developed a Retrieval-Augmented Generation (RAG) framework, utilizing\n",
      "data visualization tools to enhance interpretability of RBI guideline insights.\n",
      "• Advanced OCR for Financial Documents: Leveraged fine-tuned Vision-Language Models with MLOps pipelines\n",
      "for seamless deployment and scalability.\n",
      "• Anti-Money Laundering Detection (Neo4j GraphDB): Built a Neo4j graph database for AML investigations,\n",
      "improving fraud detection accuracy by 40% through graph-based analytics.\n",
      "• Automated Financial Reporting: Created a finance report generator, integrating dynamic web-based data\n",
      "retrieval and custom inputs to deliver actionable financial insights.\n",
      "Deng Infotech Solutions Pvt. Ltd.\n",
      "Jan 2024 - Jun 2024\n",
      "Machine Learning Intern\n",
      "Bhopal, India\n",
      "• Developed ML models for intrusion detection and fire alarm systems.\n",
      "• Implemented BERT-based NLP models for academic document classification, achieving 88% accuracy across\n",
      "multiple research domains.\n",
      "• Built and maintained reusable data integration programs in Python, implementing best practices for code effi-\n",
      "ciency and documentation.\n",
      "SKILLS\n",
      "AI Technologies\n",
      "Data Cleansing | EDA | Predictive Modeling | Prescriptive Modeling | Machine Learning | Deep Learning |\n",
      "Generative AI | Agentic AI (LangGraph, CrewAI) | NLP | LLMs | Fine-Tuning LLMs | RAG | Computer Vision\n",
      "Tools & Frameworks\n",
      "TensorFlow | PyTorch | scikit-learn | Flask | FastAPI | Docker | Git | GitHub | CI/CD\n",
      "Cloud Services\n",
      "AWS | Azure | GCP\n",
      "Databases\n",
      "MySQL | MongoDB | Vector DB (Pinecone, ChromaDB) | Graph DB (Neo4j)\n",
      "Programming\n",
      "Python\n",
      "PROȷECTS\n",
      "AI-Powered Banking Assistant | (link)\n",
      "2024\n",
      "Tools: Open Source LLM, Groq API (Llama 2), Hugging Face Transformers\n",
      "• Developed AI-powered banking assistant using NLP for smarter interactions and automation.\n",
      "• Enhanced customer support, streamlined operations, and improved user experience in Banking.\n",
      "Road Safety Sign Detection | (link)\n",
      "2023\n",
      "Tools: YOLOv8, TensorFlow, Computer Vision\n",
      "• Implemented a vision-based system for real-time road sign detection, targeting the improvement of road safety\n",
      "and traffic management.\n",
      "• Optimized model for deployment, reducing inference time to 150ms while maintaining detection accuracy.\n",
      "EDUCATION\n",
      "Bachelor of Technology (B.Tech) - Artificial Intelligence\n",
      "Jun 2020 - Jun 2024\n",
      "G. H. Raisoni College of Engineering and Management\n",
      "Pune, India\n",
      "CGPA: 8.79\n",
      "Honors in Data Science\n",
      "Jun 2022 - May 2024\n",
      "Savitribai Phule Pune University (SPPU)\n",
      "Pune, India\n",
      "CGPA: 8.5\n",
      "CERTIFICATIONS\n",
      "• Neo4j Fundamentals (Neo4j)\n",
      "• SQL Basic & Intermediate (HackerRank)\n",
      "• Python Essentials for MLOps (Coursera)\n",
      "• Certified Peer Counsellor (GHRCEM, Pune)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resume = _extract_from_pdf(\"Aditya_Varpe_AI_Engineer_Resume (5).pdf\")\n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt_template = \"\"\"\n",
    "As an experienced Applicant Tracking System (ATS) analyst,\n",
    "with profound knowledge in technology, software engineering, data science, full stack web development, cloud enginner, \n",
    "cloud developers, devops engineer and big data engineering, your role involves evaluating resumes against job descriptions.\n",
    "Recognizing the competitive job market, provide top-notch assistance for resume improvement.\n",
    "Your goal is to analyze the resume against the given job description, \n",
    "assign a percentage match based on key criteria, and pinpoint missing keywords accurately.\n",
    "resume:{text}\n",
    "description:{job_description}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description0 = \"\"\"Job description\n",
    "About the Job\n",
    "\n",
    "Job Title: AI/ML Engineer - GenAI, Summarization\n",
    "Location: Bangalore\n",
    "Experience: 2+ Years\n",
    "Job Type: Full-Time\n",
    "\n",
    "Essential Skills: AI/ML expertise with experience in Generative AI, Summarization, and NLP, along with proficiency in React.js/JavaScript.\n",
    "\n",
    "Responsibilities:\n",
    "• Generative AI: Develop models for content generation and data enhancement.\n",
    "• NLP: Apply NLP techniques for text analysis and processing.\n",
    "• Integration: Work closely with teams to incorporate AI solutions into various applications.\n",
    "• React.js/JavaScript: Build and implement AI-driven features for web and mobile platforms using React.js or JavaScript.\n",
    "\n",
    "Qualifications:\n",
    "• Education: Bachelor’s or Master’s degree in Computer Science or a related field.\n",
    "• Experience: Demonstrated experience in generative AI, data extraction, and NLP.\n",
    "• Skills: Strong proficiency in Python and familiarity with ML frameworks such as TensorFlow and PyTorch.\n",
    "\n",
    "Perks & Benefits:\n",
    "• Health and Wellness: Comprehensive healthcare coverage for you and your family, including your parents.\n",
    "• Food: Enjoy a daily buffet lunch at the office.\n",
    "• Hybrid Work Policy: Flexible work arrangement with 3 days in the office and 2 days working from home, depending on your role.\n",
    "• Professional Development: Access to workshops, funded online courses, and other learning opportunities tailored to individual needs.\n",
    "• Rewards and Recognition: Programs in place to acknowledge and celebrate your contributions and achievements.\n",
    "\n",
    "Job Location:- Bengaluru, India\n",
    "\n",
    "Salary Package:- As per Company Standards\n",
    "Apply Link:- Click Here To Apply (Apply before the link expires)\n",
    "\n",
    "[elementor-template id=\"1982\"]\n",
    "\n",
    "Off-Campus Jobs\n",
    "\n",
    "Apply Link\n",
    "\n",
    "PWC- Data Scientist\n",
    "\n",
    "Click here\n",
    "\n",
    "Genpact - Data Science Freshers\n",
    "\n",
    "Click here\n",
    "\n",
    "Fynd - Machine Learning\n",
    "\n",
    "Click here\n",
    "\n",
    "CGI - AI / ML Engineer\n",
    "\n",
    "Click here\n",
    "\n",
    "Dun & Bradstreet - Machine Learning\n",
    "\n",
    "Click here\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description1 = \"\"\"Job Description\n",
    "\n",
    "Required Information Details\n",
    "\n",
    "1 Role - Java Full Stack Developer\n",
    "\n",
    "2 Desired Experience Range - 8+ years\n",
    "\n",
    "3 Location of Requirement- PAN India\n",
    "\n",
    "Desired Skills -Technical/Behavioral\n",
    "\n",
    "Must-Have\n",
    "• Solid working experience in Java and J2EE development skills.\n",
    "• Solid understanding of the collection's frameworks.\n",
    "• Working experience in developing web services using HTTP REST/JSON and SOAP\n",
    "• Working experience in Oracle PL/SQL\n",
    "• Object-oriented and service-oriented design concepts, including knowledge of data transfer objects and associated design patterns.\n",
    "• Experience with Angular Framework, JavaScript, and CSS.\n",
    "• Comprehensive knowledge of Web design patterns and front end technologies like HTML5, JQuery and MVC framework like spring and Spring Boot.\n",
    "• Detailed knowledge of browser DOM with direct manipulation.\n",
    "• Hand-on experience with unit testing and working with continuous integration environment\n",
    "• Excellent communication skills with the ability to solicit and formalize requirements and work with end users/customers.\n",
    "• Ability to work in a semi-structured environment where requirements and priorities are dynamic.\n",
    "• Experience of working in AWS infra is must\n",
    "• Experience with agile development methodology.\n",
    "• Experience with Docker and Kubernetes is a plus\n",
    "\n",
    "Good-to-Have\n",
    "\n",
    "Responsibility of / Expectations from the Role\n",
    "\n",
    "1 Application Development back end and Front end\n",
    "\n",
    "2 Deployment in AWS environment using CI/CD pipeline Write Unit testing framework.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAs an experienced Applicant Tracking System (ATS) analyst,\\nwith profound knowledge in technology, software engineering, data science, full stack web development, cloud enginner, \\ncloud developers, devops engineer and big data engineering, your role involves evaluating resumes against job descriptions.\\nRecognizing the competitive job market, provide top-notch assistance for resume improvement.\\nYour goal is to analyze the resume against the given job description, \\nassign a percentage match based on key criteria, and pinpoint missing keywords accurately.\\nresume:Aditya Varpe\\nadi.varpe117@gmail.com | +91 8275200921\\n\\uf092github| \\uf08clinkedin\\nEXPERIENCE\\nIbind Systems Private Limited\\nJul 2024 - Present\\nAI Engineer\\nBengaluru, India\\n• Intelligent Document Management System: Orchestrated an Agentic Workflow using the LangGraph Frame-\\nwork to automate classification, summarization, and data extraction, improving document retrieval accuracy by\\n25%.\\n• Cross-Border Payment AI Solution: Developed an AI-driven fraud detection and compliance automation sys-\\ntem, reducing transaction processing time by 50%.\\n• Regulatory Compliance Automation: Developed a Retrieval-Augmented Generation (RAG) framework, utilizing\\ndata visualization tools to enhance interpretability of RBI guideline insights.\\n• Advanced OCR for Financial Documents: Leveraged fine-tuned Vision-Language Models with MLOps pipelines\\nfor seamless deployment and scalability.\\n• Anti-Money Laundering Detection (Neo4j GraphDB): Built a Neo4j graph database for AML investigations,\\nimproving fraud detection accuracy by 40% through graph-based analytics.\\n• Automated Financial Reporting: Created a finance report generator, integrating dynamic web-based data\\nretrieval and custom inputs to deliver actionable financial insights.\\nDeng Infotech Solutions Pvt. Ltd.\\nJan 2024 - Jun 2024\\nMachine Learning Intern\\nBhopal, India\\n• Developed ML models for intrusion detection and fire alarm systems.\\n• Implemented BERT-based NLP models for academic document classification, achieving 88% accuracy across\\nmultiple research domains.\\n• Built and maintained reusable data integration programs in Python, implementing best practices for code effi-\\nciency and documentation.\\nSKILLS\\nAI Technologies\\nData Cleansing | EDA | Predictive Modeling | Prescriptive Modeling | Machine Learning | Deep Learning |\\nGenerative AI | Agentic AI (LangGraph, CrewAI) | NLP | LLMs | Fine-Tuning LLMs | RAG | Computer Vision\\nTools & Frameworks\\nTensorFlow | PyTorch | scikit-learn | Flask | FastAPI | Docker | Git | GitHub | CI/CD\\nCloud Services\\nAWS | Azure | GCP\\nDatabases\\nMySQL | MongoDB | Vector DB (Pinecone, ChromaDB) | Graph DB (Neo4j)\\nProgramming\\nPython\\nPROȷECTS\\nAI-Powered Banking Assistant | (link)\\n2024\\nTools: Open Source LLM, Groq API (Llama 2), Hugging Face Transformers\\n• Developed AI-powered banking assistant using NLP for smarter interactions and automation.\\n• Enhanced customer support, streamlined operations, and improved user experience in Banking.\\nRoad Safety Sign Detection | (link)\\n2023\\nTools: YOLOv8, TensorFlow, Computer Vision\\n• Implemented a vision-based system for real-time road sign detection, targeting the improvement of road safety\\nand traffic management.\\n• Optimized model for deployment, reducing inference time to 150ms while maintaining detection accuracy.\\nEDUCATION\\nBachelor of Technology (B.Tech) - Artificial Intelligence\\nJun 2020 - Jun 2024\\nG. H. Raisoni College of Engineering and Management\\nPune, India\\nCGPA: 8.79\\nHonors in Data Science\\nJun 2022 - May 2024\\nSavitribai Phule Pune University (SPPU)\\nPune, India\\nCGPA: 8.5\\nCERTIFICATIONS\\n• Neo4j Fundamentals (Neo4j)\\n• SQL Basic & Intermediate (HackerRank)\\n• Python Essentials for MLOps (Coursera)\\n• Certified Peer Counsellor (GHRCEM, Pune)\\n\\ndescription:Job Description\\n\\nRequired Information Details\\n\\n1 Role - Java Full Stack Developer\\n\\n2 Desired Experience Range - 8+ years\\n\\n3 Location of Requirement- PAN India\\n\\nDesired Skills -Technical/Behavioral\\n\\nMust-Have\\n• Solid working experience in Java and J2EE development skills.\\n• Solid understanding of the collection's frameworks.\\n• Working experience in developing web services using HTTP REST/JSON and SOAP\\n• Working experience in Oracle PL/SQL\\n• Object-oriented and service-oriented design concepts, including knowledge of data transfer objects and associated design patterns.\\n• Experience with Angular Framework, JavaScript, and CSS.\\n• Comprehensive knowledge of Web design patterns and front end technologies like HTML5, JQuery and MVC framework like spring and Spring Boot.\\n• Detailed knowledge of browser DOM with direct manipulation.\\n• Hand-on experience with unit testing and working with continuous integration environment\\n• Excellent communication skills with the ability to solicit and formalize requirements and work with end users/customers.\\n• Ability to work in a semi-structured environment where requirements and priorities are dynamic.\\n• Experience of working in AWS infra is must\\n• Experience with agile development methodology.\\n• Experience with Docker and Kubernetes is a plus\\n\\nGood-to-Have\\n\\nResponsibility of / Expectations from the Role\\n\\n1 Application Development back end and Front end\\n\\n2 Deployment in AWS environment using CI/CD pipeline Write Unit testing framework.\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_prompt_template.format(text=resume, job_description=job_description1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "respose = llm_model.invoke(input_prompt_template.format(text=resume, job_description=job_description1)).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Resume Analysis for Java Full Stack Developer Role\n",
      "\n",
      "**Overall Match Percentage:** 15%\n",
      "\n",
      "This resume demonstrates strong skills in AI/ML and data science, but lacks the core Java/J2EE experience crucial for a Full Stack Java Developer role.  The candidate needs to significantly refocus their resume to highlight any transferable skills and acquire/showcase relevant Java experience.\n",
      "\n",
      "**Missing Keywords & Areas for Improvement:**\n",
      "\n",
      "**Critical Missing Keywords:**\n",
      "\n",
      "* **Java, J2EE:**  This is the core requirement and completely absent. The candidate needs to acquire and demonstrate Java/J2EE development experience.  Even basic projects or online courses showcasing Java skills would be beneficial.\n",
      "* **Spring, Spring Boot:**  These are essential frameworks for modern Java development and are missing.\n",
      "* **REST, SOAP:**  Experience with these web service technologies is crucial and needs to be added if present.\n",
      "* **Oracle, PL/SQL:** Database experience with Oracle and PL/SQL is a must-have and is not mentioned.\n",
      "* **HTML5, JQuery, JavaScript, CSS:** While the resume mentions front-end technologies, it lacks specific mention of these core components.  Projects demonstrating proficiency are needed.\n",
      "* **Angular:**  Experience with Angular is a key requirement and is missing.\n",
      "* **Unit Testing, CI/CD:** While CI/CD is mentioned under tools, practical experience with unit testing frameworks (e.g., JUnit, Mockito) and CI/CD pipelines needs to be explicitly stated.\n",
      "* **Agile Development Methodology:**  Mention of practical experience working in an Agile environment is missing.\n",
      "\n",
      "\n",
      "**Areas for Improvement:**\n",
      "\n",
      "* **Resume Objective/Summary:** Add a concise and targeted objective/summary statement highlighting any relevant skills for a Java developer role (e.g., problem-solving, analytical skills, quick learning) and expressing a strong interest in transitioning to Java development.\n",
      "* **Refocus Experience:**  Reframe existing project descriptions to emphasize transferable skills like problem-solving, software design, and working with complex systems.  Quantify achievements wherever possible, even if not directly related to Java.  For example, instead of focusing on the AI aspect, highlight the system design and development process.\n",
      "* **Projects:**  Develop personal projects using Java, Spring Boot, and Angular to demonstrate practical skills.  Even simple CRUD applications would be valuable.  Contribute to open-source Java projects if possible.\n",
      "* **Skills Section:**  Restructure the skills section to prioritize technologies relevant to Java development.  Move AI/ML skills lower down.  Add any relevant Java-related skills even if at a beginner level.\n",
      "* **Quantify Achievements:**  Quantify the impact of projects wherever possible, using metrics like performance improvements, cost savings, or efficiency gains.\n",
      "* **Tailor to the Job Description:**  Carefully review the job description and tailor the resume to match the specific requirements.  Use keywords from the job description throughout the resume.\n",
      "* **Address the Experience Gap:**  Acknowledge the experience gap in the objective/summary and express a strong willingness to learn and contribute.  Highlight any relevant coursework or self-learning initiatives.\n",
      "\n",
      "\n",
      "**Actionable Steps:**\n",
      "\n",
      "1. **Learn Java:** Prioritize learning Java and related technologies (Spring, Spring Boot, REST, SOAP, etc.).  Online courses, tutorials, and personal projects are excellent resources.\n",
      "2. **Build a Java Portfolio:** Develop at least 2-3 Java projects showcasing different aspects of full-stack development (e.g., CRUD application, REST API, integration with a database).\n",
      "3. **Rewrite Resume:**  Completely rewrite the resume focusing on Java skills and transferable skills.  Use the keywords identified above.\n",
      "4. **Highlight Transferable Skills:** Emphasize skills like problem-solving, analytical thinking, and adaptability, which are valuable in any software development role.\n",
      "5. **Practice Java Interview Questions:** Prepare for technical interviews by practicing common Java interview questions and coding challenges.\n",
      "\n",
      "\n",
      "By addressing these points, the candidate can significantly improve their resume and increase their chances of being considered for Java Full Stack Developer roles.  While the current experience is not directly aligned, demonstrating a proactive approach to learning and acquiring new skills will be highly valued by potential employers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(respose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# strured output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "class ResumeResponse(BaseModel):\n",
    "    \"\"\"Response containing resume analysis results.\"\"\"\n",
    "\n",
    "    company_name: str = Field(\n",
    "        description=\"Name of the company the job is for. If not mentioned, return <Not Found>.\"\n",
    "    )\n",
    "    job_description_match_score: int = Field(\n",
    "        description=\"Match score between the resume and job description, ranging from 0 to 100.\"\n",
    "    )\n",
    "    missing_keywords: str = Field(\n",
    "        description=\"Keywords missing from the resume that are present in the job description.\"\n",
    "    )\n",
    "    matching_keywords: str = Field(\n",
    "        description=\"Keywords present in both the resume and job description.\"\n",
    "    )\n",
    "    resume_edit_suggestions: str = Field(\n",
    "        description=\"integrate relevant keywords from the job description into my resume, but I want to maintain a natural flow. do this without keyword stuffing\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_response = llm_model.with_structured_output(ResumeResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd3  = \"\"\"Position Name : Aritificial Intelligence/Machine Learning Developer\n",
    "Business Unit Name : IBIND\n",
    "Team/Department : Data Science\n",
    "Location : Bangalore\n",
    "Reporting to: Technical Lead(Data Science)\n",
    "Overall Objective :\n",
    "AI Engineers at ibind are involved in the end-to-end development and deployment of machine learning models. They translate complex data into AI-driven solutions that can perform autonomously in real-time environments. This role includes writing code, deploying models to production, and continuously monitoring and updating them as needed.\n",
    "Role & Responsibility :\n",
    "Data Analysis: Collect, clean, and preprocess data from various sources to ensure data quality and integrity.\n",
    "Model Development: Design, develop, and implement machine learning models and algorithms to solve business problems.\n",
    "Model Evaluation: Evaluate model performance using appropriate metrics and improve models through iterative tuning and testing\n",
    "Data Visualization:Create visualizations to communicate insights and findings to stakeholders in a clear and concise manner.\n",
    "Systems.\n",
    "Projects\n",
    "Documentation: Maintain comprehensive documentation of data sources, methodologies, and findings.\n",
    "Graph Database Management: Leverage Neo4j graph database for complex relationship data modeling and querying.\n",
    "API Development: Design and develop REST APIs to enable integration and interaction with machine learning models and data services.\n",
    "Position Specifications\n",
    "Education Qualification (Mandatory) : Any Technical Graduate/Postgraduate\n",
    "Education Qualification (Optional / Preferrable) : NA\n",
    "Experience Required : 0 - 3 years\n",
    "Past Experience/Skills Required (Optional/ Preferrable) :\n",
    "Proficiency in programming languages such as Python or R.\n",
    "Experience with machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn).\n",
    "Familiarity with SQL and database management.\n",
    "Experience with data visualization tools (e.g., Matplotlib, Seaborn, Tableau).\n",
    "Experience with Neo4j graph database and Cypher query language\n",
    "Experience in developing REST APIs using frameworks such as Flask, Django, or FastAPI\n",
    "Experience with cloud platforms (e.g., AWS, GCP, Azure).\n",
    "Knowledge of natural language processing (NLP) techniques\n",
    "Familiarity with big data technologies (e.g., Hadoop, Spark)\n",
    "Experience with version control systems (e.g., Git).\n",
    "Knowledge of data manipulation and analysis tools (e.g., Pandas, NumPy).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = structured_response.invoke(input_prompt_template.format(text=resume, job_description=jd3)).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company_name': 'Ibind',\n",
       " 'job_description_match_score': 95,\n",
       " 'missing_keywords': 'R, SQL, Database Management, Matplotlib, Seaborn, Tableau, Cypher, Flask, Django, FastAPI, Hadoop, Spark, Pandas, NumPy, Big Data, Version Control, Git',\n",
       " 'matching_keywords': 'AI, Machine Learning, Python, TensorFlow, PyTorch, scikit-learn, Data Visualization, Neo4j, API Development, Cloud Platforms, NLP, Deep Learning, Data Cleansing, Model Development, Model Evaluation',\n",
       " 'resume_edit_suggestions': 'While your resume is already strong, subtly weaving in the following keywords can further boost its ATS compatibility:\\n* **Under \"Skills\":** Briefly mention familiarity with R alongside Python.  Add SQL and common database management systems (like MySQL, PostgreSQL, or similar) to your database list. Include popular data visualization tools like Matplotlib, Seaborn, or Tableau.  Mention experience with version control (Git) which is implied but good to state explicitly.\\n* **Within \"Projects\":** If applicable, note any use of Pandas or NumPy for data manipulation. If project scope allowed, mentioning use of big data technologies (Hadoop, Spark) or specific cloud platform components could be beneficial.  If you used Git for version control in projects, explicitly mention it.\\n* **Regarding API Development Experience:** While you mention API development, specifying experience with frameworks like Flask, Django REST Framework, or FastAPI, along with any relevant protocols (REST, GraphQL) can strengthen this area.\\n* **Neo4j Experience:** While you list Neo4j under databases and mention its use in a project, briefly mentioning Cypher query language experience under skills would be beneficial.\\n\\nRemember, integrate these keywords naturally within your existing content.  Avoid simply listing them; instead, weave them into descriptions of your skills and project contributions to demonstrate practical application.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'parse_resume' from 'src.utils' (/teamspace/studios/this_studio/src/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_resume\n\u001b[1;32m      3\u001b[0m parse_resume(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maditya_varpe_Resume (1).pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'parse_resume' from 'src.utils' (/teamspace/studios/this_studio/src/utils.py)"
     ]
    }
   ],
   "source": [
    "from src.utils import parse_resume\n",
    "\n",
    "parse_resume(\"aditya_varpe_Resume (1).pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents import parser_agnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company_name': 'IBM',\n",
       " 'sustainability': 'High',\n",
       " 'job_description_match_score': 90,\n",
       " 'missing_keywords': 'Go, Langchain, Langsmith, Docker',\n",
       " 'matching_keywords': 'AI, Machine Learning, Deep Learning, Neural Networks, NLP, Python, LangGraph, Kubernetes, Cloud, RAG, AWS, Azure, GCP',\n",
       " 'resume_experience': '< 1 year',\n",
       " 'job_description_required_experience': '2+ years'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser_agnet(job_description=jd3,resume_path=\"aditya_varpe_Resume (1).pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
